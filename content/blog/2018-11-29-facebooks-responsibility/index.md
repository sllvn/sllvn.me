---
date: "2018-11-29T22:21:00"
title: "Facebook's responsibility in an election crisis"
---

[PBS Frontline interviewed Alex Stamos](https://www.pbs.org/wgbh/frontline/interview/alex-stamos/), ex-Facebook chief security officer, on the company's response in wake of 2016 election. Some interesting quotes:

> [One] of my big fears is that we’re going to see other U.S. adversaries—Iran, North Korea, China—jump into the information warfare space in 2018, and especially in 2020.

Prescient statement, as this interview was conducted in September, a month before [the intelligence community warned of Russian, Iranian, and Chinese interference leading up to the midterms.](https://thehill.com/policy/national-security/412292-us-warns-of-ongoing-election-interference-by-russia-china-iran)

> *Do you think Facebook has earned the trust to be able to say, “Trust us; we’ve got this”?*
>
> I’m not going to answer that. I’m sorry—that’s just—everybody can make that decision for themselves.

To me, that reads "no".

> If the GRU pulled the same playbook in 2018, if right now WikiLeaks came out with the email inboxes of the five most vulnerable Democratic Senate candidates, nothing would be different in 2018 than it was in 2016, and I think we’ve got to start to think about when that happens, because that is very much a possibility if not in the midterms, in the presidential election.

Stamos makes the point that government regulation is the answer, but as [Zuckerberg had to explain the internet to our aged Senators](https://mashable.com/2018/04/10/mr-zuckerberg-meme-senate-hearing-facebook/), I wouldn't wait on government to take the lead. Tech companies understand their own platforms better than anyone else; as such, they are the most capable of understanding the consequences of under-moderation. If you build a platform, the burden of moderation falls upon *you*.
